#!/usr/bin/env python3
"""
è·å–Google Scholaræ•°æ®(ä»…æå–ID,ä¸è§£æåå­—)
"""
import json
import random
import re
import time
from gs_utils import fetch_google_scholar_page, extract_citation_count_from_gs_html, build_google_scholar_search_url


def extract_scholar_ids_from_html(html):
    """
    ä» Google Scholar HTML ä¸­æå–æ‰€æœ‰ Google Scholar ID
    
    Args:
        html: Google Scholar HTML å†…å®¹
    
    Returns:
        list: Google Scholar ID åˆ—è¡¨ï¼ˆå»é‡åï¼‰
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰ Google Scholar ID
    pattern = r'/citations\?user=([^&"\']+)'
    scholar_ids = list(set(re.findall(pattern, html)))
    return scholar_ids


def main():
    # é…ç½®å‚æ•°
    sample_size = 100  # éšæœºé‡‡æ ·çš„è®ºæ–‡æ•°é‡
    output_file = "gs_data_collection.json"
    
    # åŠ è½½è®ºæ–‡æ•°æ®
    json_file = "cv_papers_20230101_to_20250531.json"
    print(f"åŠ è½½è®ºæ–‡æ•°æ®: {json_file}")
    
    with open(json_file, 'r', encoding='utf-8') as f:
        all_papers = json.load(f)
    
    print(f"æ€»è®ºæ–‡æ•°: {len(all_papers)}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²å¤„ç†çš„ç»“æœæ–‡ä»¶
    processed_arxiv_ids = set()
    existing_results = []
    
    try:
        with open(output_file, 'r', encoding='utf-8') as f:
            existing_results = json.load(f)
            processed_arxiv_ids = {paper.get('arxiv_id') for paper in existing_results if paper.get('arxiv_id')}
            print(f"å‘ç°å·²å¤„ç†çš„ç»“æœæ–‡ä»¶: {output_file}")
            print(f"å·²å¤„ç†çš„è®ºæ–‡æ•°: {len(processed_arxiv_ids)}")
    except FileNotFoundError:
        print(f"æœªæ‰¾åˆ°å·²å¤„ç†çš„ç»“æœæ–‡ä»¶ï¼Œå°†ä»å¤´å¼€å§‹")
    except Exception as e:
        print(f"âš ï¸  è¯»å–å·²å¤„ç†ç»“æœæ–‡ä»¶æ—¶å‡ºé”™: {e}ï¼Œå°†ä»å¤´å¼€å§‹")
    
    # ä»æ‰€æœ‰è®ºæ–‡ä¸­ç§»é™¤å·²å¤„ç†çš„è®ºæ–‡
    remaining_papers = [paper for paper in all_papers if paper.get('arxiv_id') not in processed_arxiv_ids]
    
    print(f"å‰©ä½™æœªå¤„ç†çš„è®ºæ–‡æ•°: {len(remaining_papers)}")
    print(f"éšæœºé‡‡æ ·: {sample_size} ç¯‡è®ºæ–‡\n")
    
    if len(remaining_papers) == 0:
        print("âš ï¸  æ‰€æœ‰è®ºæ–‡éƒ½å·²å¤„ç†å®Œæˆï¼")
        return
    
    if len(remaining_papers) < sample_size:
        print(f"âš ï¸  å‰©ä½™è®ºæ–‡æ•° ({len(remaining_papers)}) å°‘äºé‡‡æ ·æ•°é‡ ({sample_size})ï¼Œå°†å¤„ç†æ‰€æœ‰å‰©ä½™è®ºæ–‡")
        sample_size = len(remaining_papers)
    
    # éšæœºé‡‡æ · n ç¯‡è®ºæ–‡
    sampled_papers = random.sample(remaining_papers, sample_size)
    
    results = existing_results.copy()  # ä¿ç•™å·²æœ‰ç»“æœ
    save_interval = 10  # æ¯10ä¸ªè®ºæ–‡ä¿å­˜ä¸€æ¬¡
    initial_count = len(existing_results)  # è®°å½•åˆå§‹æ•°é‡
    
    for idx, paper in enumerate(sampled_papers, 1):
        arxiv_id = paper.get('arxiv_id', '')
        arxiv_authors = paper.get('authors', [])
        title = paper.get('title', '')
        
        print(f"[{idx}/{len(sampled_papers)}] arXiv ID: {arxiv_id}")
        print(f"  æ ‡é¢˜: {title[:60]}...")
        
        # æ„å»ºæœç´¢ URLï¼ˆæ— è®ºæˆåŠŸä¸å¦éƒ½è¦ä¿å­˜ï¼‰
        gs_search_url = build_google_scholar_search_url(title, arxiv_authors)
        
        # æ„å»ºç»“æœï¼šä¿ç•™åŸå§‹è®ºæ–‡çš„æ‰€æœ‰ä¿¡æ¯
        result = paper.copy()
        # ç§»é™¤ authors å­—æ®µï¼Œä½¿ç”¨ arxiv_authors æ›¿ä»£
        if 'authors' in result:
            result['arxiv_authors'] = result.pop('authors')
        else:
            result['arxiv_authors'] = arxiv_authors
        
        # æ·»åŠ  Google Scholar ç›¸å…³å­—æ®µ
        result['gs_search_url'] = gs_search_url
        
        # è·å– Google Scholar é¡µé¢
        try:
            html = fetch_google_scholar_page(title, arxiv_authors)
            
            if html:
                # æå– Google Scholar IDï¼ˆä»…IDï¼Œä¸è§£æåå­—ï¼‰
                scholar_ids = extract_scholar_ids_from_html(html)
                
                # æå–å¼•ç”¨æ•°é‡
                citation_count = extract_citation_count_from_gs_html(html, title=title)
                
                result['gs_search_success'] = True
                result['gs_authors'] = scholar_ids  # ç›´æ¥ä¿å­˜IDåˆ—è¡¨
                result['citation_count'] = citation_count
                # æˆåŠŸæ—¶ä¸è®¾ç½® error_type
                
                print(f"  âœ… æˆåŠŸæå–æ•°æ®: æ‰¾åˆ° {len(scholar_ids)} ä¸ª Scholar ID")
            else:
                print(f"  âŒ æ— æ³•è·å– Google Scholar é¡µé¢")
                result['gs_search_success'] = False
                result['gs_authors'] = []
                result['citation_count'] = None
                result['error_type'] = "fetch_failed"
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶é”™è¯¯
            error_str = str(e).lower()
            if 'timeout' in error_str or 'timed out' in error_str:
                error_type = "timeout"
                print(f"  âŒ è¯·æ±‚è¶…æ—¶")
            else:
                error_type = "fetch_failed"
                print(f"  âŒ è·å–å¤±è´¥: {e}")
            
            result['gs_search_success'] = False
            result['gs_authors'] = []
            result['citation_count'] = None
            result['error_type'] = error_type
        
        results.append(result)
        print()
        
        # æ¯å¤„ç†save_intervalä¸ªè®ºæ–‡å°±ä¿å­˜ä¸€æ¬¡
        if idx % save_interval == 0:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"  ğŸ’¾ å·²ä¿å­˜ {len(results)} ç¯‡è®ºæ–‡åˆ° {output_file}\n")
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(1)
    
    # æœ€åä¿å­˜ä¸€æ¬¡ï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½è¢«ä¿å­˜ï¼ˆå¤„ç†å‰©ä½™ä¸è¶³save_intervalçš„è®ºæ–‡ï¼‰
    if len(sampled_papers) % save_interval != 0:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"  ğŸ’¾ æœ€ç»ˆä¿å­˜ {len(results)} ç¯‡è®ºæ–‡åˆ° {output_file}\n")
    
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"æ€»å…±å¤„ç†: {len(results)} ç¯‡è®ºæ–‡ï¼ˆåŒ…å«ä¹‹å‰å·²å¤„ç†çš„ {initial_count} ç¯‡ï¼‰")
    success_count = sum(1 for r in results if r.get('gs_search_success', False))
    print(f"æˆåŠŸè·å–: {success_count} ç¯‡")
    print(f"æœ¬æ¬¡æ–°å¢: {len(results) - initial_count} ç¯‡")


if __name__ == "__main__":
    main()

