import json
import zipfile
from collections import defaultdict

print("ğŸ“‚ ç¬¬1æ­¥: è¯»å–æ‰€æœ‰ä½œè€…æ¡£æ¡ˆ...")
author_names = {}  # author_id -> name
zip_path = 'crawling_profiles/all_author_profiles_cv.zip'

with zipfile.ZipFile(zip_path, 'r') as zip_file:
    file_list = zip_file.namelist()
    total_authors = len(file_list)
    
    for idx, filename in enumerate(file_list):
        if idx % 5000 == 0:
            print(f"  å¤„ç†ä¸­... {idx}/{total_authors}")
        
        # æå–ä½œè€… ID (ä» author_XXX.json ä¸­æå– XXX)
        if filename.startswith('author_') and filename.endswith('.json'):
            author_id = filename[7:-5]  # å»æ‰ 'author_' å’Œ '.json'
            
            # è¯»å– JSON è·å–ä½œè€…å§“å
            with zip_file.open(filename) as f:
                try:
                    profile = json.load(f)
                    name = profile.get('author_info', {}).get('name', 'Unknown')
                    author_names[author_id] = name
                except:
                    author_names[author_id] = 'Unknown'

print(f"âœ… è¯»å–äº† {len(author_names)} ä¸ªä½œè€…æ¡£æ¡ˆ")

print("\nğŸ“„ ç¬¬2æ­¥: è¯»å–è®ºæ–‡æ•°æ®å¹¶æ„å»ºæ˜ å°„...")
with open('gs_data_collection.json', 'r') as f:
    papers = json.load(f)

# æ„å»ºç»“æœå­—å…¸
author_papers = {}
for author_id, name in author_names.items():
    author_papers[author_id] = {
        "name": name,
        "papers": []
    }

# éå†æ‰€æœ‰è®ºæ–‡ï¼Œå°†è®ºæ–‡æ·»åŠ åˆ°å¯¹åº”ä½œè€…
paper_count = 0
for idx, paper in enumerate(papers):
    if idx % 10000 == 0:
        print(f"  å¤„ç†è®ºæ–‡... {idx}/{len(papers)}")
    
    arxiv_id = paper.get('arxiv_id')
    title = paper.get('title', 'Unknown')
    gs_authors = paper.get('gs_authors', [])
    
    if arxiv_id and gs_authors:
        paper_info = {
            'arxiv_id': arxiv_id,
            'title': title
        }
        for author_id in gs_authors:
            if author_id in author_papers:
                author_papers[author_id]['papers'].append(paper_info)
                paper_count += 1

print(f"âœ… å¤„ç†äº† {len(papers)} ç¯‡è®ºæ–‡ï¼Œå»ºç«‹äº† {paper_count} ä¸ªä½œè€…-è®ºæ–‡å…³è”")

print("\nğŸ’¾ ç¬¬3æ­¥: ä¿å­˜ç»“æœ...")
with open('author_to_papers.json', 'w') as f:
    json.dump(author_papers, f, indent=2, ensure_ascii=False)

# ç»Ÿè®¡ä¿¡æ¯
authors_with_papers = sum(1 for v in author_papers.values() if len(v['papers']) > 0)
total_paper_links = sum(len(v['papers']) for v in author_papers.values())

print(f"\nğŸ“Š ç»Ÿè®¡:")
print(f"- æ€»ä½œè€…æ•°: {len(author_papers)}")
print(f"- æœ‰è®ºæ–‡çš„ä½œè€…æ•°: {authors_with_papers}")
print(f"- æ— è®ºæ–‡çš„ä½œè€…æ•°: {len(author_papers) - authors_with_papers}")
print(f"- æ€»ä½œè€…-è®ºæ–‡å…³è”æ•°: {total_paper_links}")
print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: author_to_papers.json")

