#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨è´ªå¿ƒç®—æ³•æ‰¾åˆ°æœ€å°çš„è®ºæ–‡é›†åˆ
ç›®æ ‡ï¼šè¦†ç›–æ‰€æœ‰ active_authors.json ä¸­å®šä¹‰çš„æ´»è·ƒä½œè€…
"""

import os
import json
import time

def main():
    print("="*80)
    print("æœ€å°è®ºæ–‡é›†åˆæŸ¥æ‰¾ - åŸºäºæ´»è·ƒä½œè€…")
    print("="*80)
    print("ç›®æ ‡ï¼šè¦†ç›–æ‰€æœ‰ active_authors.json ä¸­çš„æ´»è·ƒä½œè€…")
    print("="*80)
    print()
    
    start_time = time.time()
    
    # 1. åŠ è½½æ´»è·ƒä½œè€…
    print("æ­¥éª¤ 1: åŠ è½½æ´»è·ƒä½œè€…...")
    active_authors_file = 'active_authors.json'
    
    if not os.path.exists(active_authors_file):
        print(f"é”™è¯¯: æ–‡ä»¶ '{active_authors_file}' ä¸å­˜åœ¨ï¼")
        print("è¯·å…ˆè¿è¡Œ analyze_active_authors.py ç”Ÿæˆæ´»è·ƒä½œè€…åˆ—è¡¨ã€‚")
        return
    
    with open(active_authors_file, 'r', encoding='utf-8') as f:
        active_authors_data = json.load(f)
    
    target_authors = {author['name'] for author in active_authors_data}
    print(f"âœ“ åŠ è½½äº† {len(target_authors):,} ä½æ´»è·ƒä½œè€… ({time.time()-start_time:.1f}s)\n")
    
    # 2. åŠ è½½æ‰€æœ‰è®ºæ–‡
    print("æ­¥éª¤ 2: åŠ è½½æ‰€æœ‰è®ºæ–‡...")
    step_start = time.time()
    folder = 'conference_papers'
    
    if not os.path.exists(folder):
        print(f"é”™è¯¯: æ–‡ä»¶å¤¹ '{folder}' ä¸å­˜åœ¨ï¼")
        return
    
    all_papers = []
    files = sorted([f for f in os.listdir(folder) if f.endswith('.json')])
    
    if not files:
        print(f"é”™è¯¯: åœ¨ '{folder}' ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶ï¼")
        return
    
    for filename in files:
        filepath = os.path.join(folder, filename)
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                papers = json.load(f)
                for paper in papers:
                    paper['source_file'] = filename
                all_papers.extend(papers)
        except (json.JSONDecodeError, FileNotFoundError) as e:
            print(f"è­¦å‘Š: è·³è¿‡æ–‡ä»¶ {filename}, é”™è¯¯: {e}")
            continue
    
    print(f"âœ“ åŠ è½½äº† {len(all_papers):,} ç¯‡è®ºæ–‡ ({time.time()-step_start:.1f}s)\n")
    
    # 3. é¢„å¤„ç†ï¼šåªä¿ç•™åŒ…å«ç›®æ ‡ä½œè€…çš„è®ºæ–‡
    print("æ­¥éª¤ 3: é¢„å¤„ç†è®ºæ–‡...")
    step_start = time.time()
    relevant_papers = []
    for i, paper in enumerate(all_papers):
        if i % 5000 == 0:
            print(f"  å¤„ç†ä¸­: {i:,}/{len(all_papers):,}", end='\r', flush=True)
        
        # æ¸…ç†ä½œè€…åå­—ï¼Œå»é™¤ç©ºå€¼
        authors = set()
        for author in paper.get('authors', []):
            if author and str(author).strip():
                authors.add(str(author).strip())
        
        # åªä¿ç•™è‡³å°‘æœ‰ä¸€ä¸ªç›®æ ‡ä½œè€…çš„è®ºæ–‡
        if authors & target_authors:
            paper['target_authors'] = authors & target_authors
            relevant_papers.append(paper)
    
    print(f"\râœ“ è¿‡æ»¤åˆ° {len(relevant_papers):,} ç¯‡ç›¸å…³è®ºæ–‡ ({time.time()-step_start:.1f}s)")
    print(f"  å‡å°‘äº† {len(all_papers) - len(relevant_papers):,} ç¯‡ ({(1-len(relevant_papers)/len(all_papers))*100:.1f}%)\n")
    
    # 4. è´ªå¿ƒç®—æ³•  
    print("æ­¥éª¤ 4: è¿è¡Œè´ªå¿ƒç®—æ³•...")
    print("-"*80)
    
    uncovered = target_authors.copy()
    selected = []
    iteration = 0
    algo_start = time.time()
    
    while uncovered and relevant_papers:
        iteration += 1
        iter_start = time.time()
        
        # æ‰¾åˆ°è¦†ç›–æœ€å¤šæœªè¦†ç›–ä½œè€…çš„è®ºæ–‡
        best_idx = -1
        best_count = 0
        
        print(f"  ç¬¬ {iteration:4d} è½®: æ£€æŸ¥ {len(relevant_papers):,} ç¯‡è®ºæ–‡...", end='', flush=True)
        
        for i, paper in enumerate(relevant_papers):
            # æ¯5000ç¯‡æ‰“å°è¿›åº¦
            if i > 0 and i % 5000 == 0:
                print(f"\r  ç¬¬ {iteration:4d} è½®: æ£€æŸ¥ä¸­ {i:,}/{len(relevant_papers):,}...", end='', flush=True)
            
            count = len(paper['target_authors'] & uncovered)
            if count > best_count:
                best_count = count
                best_idx = i
        
        if best_idx == -1 or best_count == 0:
            print("\râœ— æ— æ³•æ‰¾åˆ°æ›´å¤šè¦†ç›–")
            break
        
        # é€‰æ‹©æœ€ä½³è®ºæ–‡
        best_paper = relevant_papers.pop(best_idx)
        selected.append(best_paper)
        uncovered -= best_paper['target_authors']
        
        # ä¼˜åŒ–ï¼šç§»é™¤ä¸å†èƒ½è¦†ç›–ä»»ä½•æœªè¦†ç›–ä½œè€…çš„è®ºæ–‡
        if iteration % 10 == 0:  # æ¯10è½®æ¸…ç†ä¸€æ¬¡ï¼Œé¿å…æ¯è½®éƒ½æ¸…ç†å½±å“æ€§èƒ½
            relevant_papers = [p for p in relevant_papers if p['target_authors'] & uncovered]
        
        coverage_pct = (len(target_authors) - len(uncovered)) / len(target_authors) * 100
        iter_time = time.time() - iter_start
        
        print(f"\r  ç¬¬ {iteration:4d} è½®: è¦†ç›– {len(target_authors)-len(uncovered):6,}/{len(target_authors):,} "
              f"({coverage_pct:5.1f}%), æ–°å¢ {best_count:3d} ä½, "
              f"å·²é€‰ {len(selected):4,} ç¯‡, ç”¨æ—¶ {iter_time:.1f}s")
        
        # å¦‚æœè¦†ç›–ç‡è¶…è¿‡99.5%ï¼Œå¯ä»¥è€ƒè™‘æå‰ç»“æŸ
        if coverage_pct >= 99.5:
            print(f"\n  â„¹ï¸  å·²è¦†ç›– {coverage_pct:.2f}%ï¼Œæ¥è¿‘å®Œæˆ")
    
    print("-"*80)
    print(f"âœ“ ç®—æ³•å®Œæˆï¼Œç”¨æ—¶ {time.time()-algo_start:.1f}s\n")
    
    # 5. éªŒè¯
    print("æ­¥éª¤ 5: éªŒè¯è¦†ç›–...")
    covered = set()
    for paper in selected:
        covered.update(paper.get('authors', []))
    
    coverage = len(covered & target_authors)
    print(f"âœ“ è¦†ç›–äº† {coverage:,} / {len(target_authors):,} ä½ç›®æ ‡ä½œè€…")
    print(f"âœ“ è¦†ç›–ç‡: {coverage / len(target_authors) * 100:.2f}%\n")
    
    # 6. ä¿å­˜ç»“æœ
    print("æ­¥éª¤ 6: ä¿å­˜ç»“æœ...")
    
    # æ¸…ç†è®ºæ–‡æ•°æ®ï¼ˆç§»é™¤ä¸´æ—¶å­—æ®µï¼‰
    for paper in selected:
        if 'target_authors' in paper:
            del paper['target_authors']
    
    # ä¿å­˜JSON
    with open('minimal_paper_set.json', 'w', encoding='utf-8') as f:
        json.dump(selected, f, indent=2, ensure_ascii=False)
    print(f"âœ“ è®ºæ–‡é›†åˆå·²ä¿å­˜åˆ°: minimal_paper_set.json")
    
    # ä¿å­˜æŠ¥å‘Š
    with open('minimal_paper_set_report.txt', 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("æœ€å°è®ºæ–‡é›†åˆ - åŸºäºæ´»è·ƒä½œè€…çš„è´ªå¿ƒç®—æ³•ç»“æœ\n")
        f.write("="*80 + "\n\n")
        
        f.write(f"æ€»è®ºæ–‡æ•°: {len(all_papers):,}\n")
        f.write(f"ç›®æ ‡ä½œè€…æ•°ï¼ˆæ¥è‡ª active_authors.jsonï¼‰: {len(target_authors):,}\n")
        f.write(f"é€‰ä¸­çš„è®ºæ–‡æ•°: {len(selected):,}\n")
        f.write(f"å‹ç¼©æ¯”: {len(selected) / len(all_papers) * 100:.2f}%\n")
        f.write(f"è¦†ç›–çš„ä½œè€…æ•°: {coverage:,}\n")
        f.write(f"è¦†ç›–ç‡: {coverage / len(target_authors) * 100:.2f}%\n")
        f.write(f"æ€»ç”¨æ—¶: {time.time() - start_time:.1f} ç§’\n")
        
        f.write("\n" + "="*80 + "\n")
        f.write("é€‰ä¸­çš„è®ºæ–‡åˆ—è¡¨\n")
        f.write("="*80 + "\n\n")
        
        for i, paper in enumerate(selected, 1):
            f.write(f"{i}. {paper['title']}\n")
            f.write(f"   æ¥æº: {paper.get('venue', 'N/A')}\n")
            authors = paper.get('authors', [])
            f.write(f"   ä½œè€… ({len(authors)}): {', '.join(authors[:5])}")
            if len(authors) > 5:
                f.write(f" ... ç­‰ {len(authors) - 5} ä½")
            f.write("\n\n")
    
    print(f"âœ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: minimal_paper_set_report.txt")
    
    # æœ€ç»ˆç»Ÿè®¡
    print("\n" + "="*80)
    print("æœ€ç»ˆç»Ÿè®¡")
    print("="*80)
    print(f"åŸå§‹è®ºæ–‡æ•°:     {len(all_papers):6,} ç¯‡")
    print(f"æœ€å°è®ºæ–‡é›†åˆ:   {len(selected):6,} ç¯‡")
    print(f"å‹ç¼©æ¯”:         {len(selected) / len(all_papers) * 100:6.2f}%")
    print(f"èŠ‚çœ:           {len(all_papers) - len(selected):6,} ç¯‡ ({(1 - len(selected) / len(all_papers)) * 100:.2f}%)")
    print(f"æ€»ç”¨æ—¶:         {time.time() - start_time:6.1f} ç§’")
    print()
    print(f"ğŸ‰ ä½ åªéœ€è¦å¤„ç† {len(selected):,} ç¯‡è®ºæ–‡ï¼Œè€Œä¸æ˜¯ {len(all_papers):,} ç¯‡ï¼")
    print(f"ğŸ’° è¿™å°†èŠ‚çœ {(1 - len(selected) / len(all_papers)) * 100:.1f}% çš„è®¡ç®—æ—¶é—´ï¼")


if __name__ == '__main__':
    main()

